{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# HPC Project: GPU Acceleration Analysis\n",
                "## Academic Title: Performance Analysis of Parallel Matrix Computation using CUDA-Enabled GPUs\n",
                "\n",
                "**Student Name:** [Your Name]  \n",
                "**Course:** High Performance Computing (MSc)  \n",
                "**Date:** [Today's Date]\n",
                "\n",
                "---\n",
                "\n",
                "### Abstract\n",
                "This notebook demonstrates the significant performance advantages of GPU acceleration over CPU for computationally intensive tasks. Specifically, we benchmark large-scale Matrix Multiplication ($C = A \\times B$) using **NVIDIA CUDA** cores via the **CuPy** library, comparing it against the CPU-based **NumPy** implementation. Results typically show a speedup of **50x to 1000x** depending on matrix size."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 1: System Check (GPU Availability)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 2: Install/Verify Dependencies\n",
                "Google Colab typically creates an environment where CuPy is pre-installed or easily installable."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import subprocess\n",
                "\n",
                "def install(package):\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
                "\n",
                "try:\n",
                "    import cupy as cp\n",
                "    print(\"CuPy is already installed.\")\n",
                "    print(f\"CuPy Version: {cp.__version__}\")\n",
                "except ImportError:\n",
                "    print(\"Installing CuPy...\")\n",
                "    install(\"cupy-cuda12x\")  # Adjust CUDA version if necessary for Colab runtime\n",
                "    import cupy as cp\n",
                "\n",
                "import numpy as np\n",
                "import time\n",
                "import matplotlib.pyplot as plt\n",
                "print(\"Libraries loaded successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 3: CPU Implementation (NumPy)\n",
                "We define a function for CPU-based matrix multiplication."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_cpu_benchmark(size):\n",
                "    \"\"\"\n",
                "    Performs Matrix Multiplication on CPU using NumPy.\n",
                "    \"\"\"\n",
                "    print(f\"[CPU] Allocating {size}x{size} matrices...\")\n",
                "    A = np.random.rand(size, size).astype(np.float32)\n",
                "    B = np.random.rand(size, size).astype(np.float32)\n",
                "    \n",
                "    print(f\"[CPU] Starting computation for N={size}...\")\n",
                "    start_time = time.time()\n",
                "    C = np.dot(A, B)\n",
                "    end_time = time.time()\n",
                "    \n",
                "    execution_time = end_time - start_time\n",
                "    print(f\"[CPU] Finished in {execution_time:.4f} seconds.\")\n",
                "    return execution_time"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 4: GPU Implementation (CuPy)\n",
                "We define a function for GPU-based matrix multiplication, ensuring we handle memory transfer (allocation on device) and synchronization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_gpu_benchmark(size):\n",
                "    \"\"\"\n",
                "    Performs Matrix Multiplication on GPU using CuPy.\n",
                "    \"\"\"\n",
                "    print(f\"[GPU] Allocating {size}x{size} matrices on Device...\")\n",
                "    A_gpu = cp.random.rand(size, size, dtype=cp.float32)\n",
                "    B_gpu = cp.random.rand(size, size, dtype=cp.float32)\n",
                "    \n",
                "    # Warm-up (important for CUDA context init)\n",
                "    cp.dot(A_gpu[:10], B_gpu[:10])\n",
                "    cp.cuda.Stream.null.synchronize()\n",
                "    \n",
                "    print(f\"[GPU] Starting computation for N={size}...\")\n",
                "    # Create CUDA events for precise timing\n",
                "    start_event = cp.cuda.Event()\n",
                "    end_event = cp.cuda.Event()\n",
                "    \n",
                "    start_event.record()\n",
                "    C_gpu = cp.dot(A_gpu, B_gpu)\n",
                "    end_event.record()\n",
                "    end_event.synchronize()\n",
                "    \n",
                "    execution_time = cp.cuda.get_elapsed_time(start_event, end_event) / 1000.0\n",
                "    print(f\"[GPU] Finished in {execution_time:.4f} seconds.\")\n",
                "    return execution_time"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 5: Comparative Benchmark\n",
                "We run both implementations and compare the results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "MATRIX_SIZE = 4000  # Adjust this size based on available RAM (4000-8000 is good for T4)\n",
                "\n",
                "print(f\"Running Benchmark (N={MATRIX_SIZE})...\")\n",
                "print(\"=\"*40)\n",
                "\n",
                "# CPU Run\n",
                "t_cpu = run_cpu_benchmark(MATRIX_SIZE)\n",
                "\n",
                "# GPU Run\n",
                "try:\n",
                "    t_gpu = run_gpu_benchmark(MATRIX_SIZE)\n",
                "except Exception as e:\n",
                "    t_gpu = float('inf')\n",
                "    print(f\"GPU Failed: {e}\")\n",
                "\n",
                "# Calculate Speedup\n",
                "speedup = t_cpu / t_gpu if t_gpu > 0 else 0\n",
                "\n",
                "print(\"=\"*40)\n",
                "print(f\"RESULTS summary (N={MATRIX_SIZE}):\")\n",
                "print(f\"CPU Time: {t_cpu:.4f} s\")\n",
                "print(f\"GPU Time: {t_gpu:.4f} s\")\n",
                "print(f\"Speedup:  {speedup:.2f}x\")\n",
                "print(\"=\"*40)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Step 6: Visualization & Report generation\n",
                "Visualizing the difference."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Simple Bar Chart\n",
                "labels = ['CPU (NumPy)', 'GPU (CuPy)']\n",
                "times = [t_cpu, t_gpu]\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.bar(labels, times, color=['blue', 'green'])\n",
                "plt.ylabel('Execution Time (seconds)')\n",
                "plt.title(f'Execution Time Comparison (N={MATRIX_SIZE})')\n",
                "plt.yscale('log') # Log scale because difference is huge\n",
                "plt.grid(axis='y', which='both', linestyle='--', alpha=0.7)\n",
                "plt.show()\n",
                "\n",
                "# Save results to file\n",
                "with open('benchmark_results.txt', 'w') as f:\n",
                "    f.write(f\"Matrix Size: {MATRIX_SIZE}\\n\")\n",
                "    f.write(f\"CPU Time: {t_cpu:.6f} s\\n\")\n",
                "    f.write(f\"GPU Time: {t_gpu:.6f} s\\n\")\n",
                "    f.write(f\"Speedup: {speedup:.2f}x\\n\")\n",
                "print(\"Results saved to benchmark_results.txt\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}