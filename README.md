# Performance Analysis of Parallel Matrix Computation (CPU vs GPU)

ğŸ“Œ **Project Overview**

This project demonstrates the practical benefits of **High Performance Computing (HPC)** by benchmarking large-scale matrix multiplication on **CPU vs GPU**.

A comparative study is performed between:

* **CPU-based** serial computation using **NumPy**
* **GPU-accelerated** parallel computation using **CuPy** (CUDA)

The project is designed to run out-of-the-box on **Google Colab** using an **NVIDIA Tesla T4 GPU**.

ğŸš€ **Motivation**

In modern scientific computing, machine learning, and data analytics, sequential CPU execution often becomes a performance bottleneck. This project aims to:

1. Quantify the performance improvement achieved through GPU acceleration
2. Demonstrate CUDA-enabled parallel computing using high-level Python libraries
3. Provide an academically sound, reproducible reference for MSc-level HPC coursework

ğŸ›  **Technologies Used**

* **Language:** Python 3.10
* **CPU Computation:** NumPy
* **GPU Computation:** CuPy
* **Parallel Platform:** NVIDIA CUDA
* **Execution Environment:** Google Colab (Jupyter Notebook)

ğŸ“‚ **Repository Structure**

```
HPC-Matrix-Benchmark-GPU/
â”œâ”€â”€ colab_notebook.ipynb        # MAIN FILE (Run on Google Colab)
â”œâ”€â”€ README.md                   # Project Documentation
â”œâ”€â”€ requirements.txt            # Optional local dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ cpu_version.py          # CPU implementation (NumPy)
â”‚   â”œâ”€â”€ gpu_version.py          # GPU implementation (CuPy)
â”‚   â””â”€â”€ benchmark.py            # Benchmark driver
â”œâ”€â”€ results/                    # Benchmark logs / outputs
â””â”€â”€ report/
    â””â”€â”€ HPC_Project_Report.md   # Full academic project report
```

âš¡ **How to Run**

**Option 1: Google Colab (Recommended)**

1. Download `colab_notebook.ipynb` from this repository
2. Upload it to [https://colab.research.google.com](https://colab.research.google.com)
3. Go to **Runtime â†’ Change runtime type**
4. Select **GPU (T4)** as the hardware accelerator
5. Click **Runtime â†’ Run all**

âœ… *No local setup required*

**Option 2: Local Execution (Requires NVIDIA GPU)**

Requires:

* NVIDIA GPU
* CUDA drivers
* Compatible CuPy installation

```bash
# Clone the repository
git clone https://github.com/partha392/HPC-Matrix-Benchmark-GPU.git
cd HPC-Matrix-Benchmark-GPU

# Install dependencies
pip install -r requirements.txt

# Run benchmark
python src/benchmark.py
```

ğŸ“Š **Sample Output**

*(Observed on Google Colab with NVIDIA Tesla T4 GPU)*

```text
Matrix Size: 4000 x 4000
CPU Time: 12.8 â€“ 18.1 sec
GPU Time: 0.08 â€“ 0.15 sec
-------------------------
Observed Speedup: ~80x â€“ 180x
```

âš ï¸ *Exact performance may vary due to shared cloud infrastructure and runtime conditions.*

ğŸ“œ **Academic Report**

A detailed academic report is available in the `report/` directory, covering:

* HPC and CUDA architecture overview
* Experimental methodology
* Performance benchmarking and speedup analysis
* Limitations and future scope

ğŸ“„ File: [report/HPC_Project_Report.md](report/HPC_Project_Report.md)

ğŸ¤ **Contributions & Extensions**

This is an academic HPC benchmark project.
Possible extensions include:

* Multi-GPU benchmarking (NCCL)
* Mixed-precision computation using Tensor Cores
* Additional benchmarks (FFT, Monte Carlo, reductions)

Suggestions and improvements are welcome.

ğŸ“ **License**

This project is licensed under the MIT License and is free to use for educational and academic purposes.
